% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tool_groq.R
\name{query_groq}
\alias{query_groq}
\title{Query the Groq API with a Prompt}
\usage{
query_groq(prompt, config)
}
\arguments{
\item{prompt}{A character string containing the prompt text for the model.}

\item{config}{A named list with Groq configuration parameters:
\describe{
\item{\code{api_key}}{Your Groq API key (as a string).}
\item{\code{url}}{Groq API endpoint (e.g., \code{"https://api.groq.com/openai/v1/chat/completions"}).}
\item{\code{model}}{Model name to use, such as \code{"llama3-70b-8192"}.}
}}
}
\value{
A character string with the model's generated response.
}
\description{
Sends a prompt to the Groq-hosted LLM (e.g., LLaMA 3) using the OpenAI-compatible API format.
This function assumes a standard completion interface similar to OpenAIâ€™s chat completion endpoint.
}
\examples{
config <- tool_set_config("groq")
query_groq("Write a haiku about LLMs.", config)

}
